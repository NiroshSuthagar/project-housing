{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db49ed31",
   "metadata": {},
   "source": [
    "# Baseline Naive Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9151ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb3c2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 2.14.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa23d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (2.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55935c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stratified features \n",
    "X_train = pd.read_parquet('data_output/prod_features/X_train.parquet')\n",
    "y_train = pd.read_parquet('data_output/prod_features/y_train.parquet')\n",
    "X_test = pd.read_parquet('data_output/prod_features/X_test.parquet')\n",
    "y_test = pd.read_parquet('data_output/prod_features/y_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0cbee1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioning Complete: 87 Partitions Created\n",
      "Partioning Complete: 87 Partitions Created\n"
     ]
    }
   ],
   "source": [
    "# Partitioning data into chunks of 100 records (to monitor cost efficiency)\n",
    "output_dir = 'data_output/prod_features/json_test_files/'\n",
    "partition_size = 100\n",
    "\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "df_to_chunk ={'X_test':X_test, 'y_test':y_test}\n",
    "\n",
    "for name, file in df_to_chunk.items():\n",
    "\n",
    "    for chunk_id, chunk_df in iter(file.groupby(np.arange(len(file)) // partition_size)):\n",
    "        file_path = f'{output_dir}{name}_part_{chunk_id}.jsonl'\n",
    "        chunk_df.to_json(file_path,orient='records', lines=True)\n",
    "\n",
    "    print(f'Partioning Complete: {chunk_id} Partitions Created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c3dccbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Predictions using OpenAI \n",
    "class NaiveAgent:\n",
    "    def __init__(self, system_prompt, model = 'gpt-5-nano' ):\n",
    "        load_dotenv()\n",
    "        \n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError('OpenAI API Key not found in .env')\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.user_prompt = None\n",
    "        self.base_data_path = Path('data_output/prod_features/json_test_files/')\n",
    "        self.output_dir = Path('data_output/agentic_outputs')\n",
    "        self.input_data = None\n",
    "    \n",
    "    def JSON_read(self, file_name, output_dir='data_output'):\n",
    "        try:\n",
    "            data = []\n",
    "            self.file_path = self.base_data_path / file_name\n",
    "            with self.file_path.open('r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line.strip()))\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f'Error Loading JSON: \\n{e}')\n",
    "            return None\n",
    "    \n",
    "    def call_agent(self):   \n",
    "        str_user_prompt = str(self.user_prompt)\n",
    "        str_sys_prompt = str(self.system_prompt)\n",
    "        \n",
    "        agent_response = self.client.responses.create(\n",
    "            model = self.model,\n",
    "            input = [\n",
    "                {\n",
    "                    \"role\":\"system\",\n",
    "                    \"content\":str_sys_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":str_user_prompt\n",
    "                }\n",
    "            ],\n",
    "            text = {\n",
    "                \"format\":{\n",
    "                    \"type\":\"json_schema\",\n",
    "                    \"name\":\"agent_output\",\n",
    "                    \"strict\":True,\n",
    "                    \"schema\": {\n",
    "                        \"type\":\"object\",\n",
    "                        \"properties\":{\n",
    "                                        \"price\":{\"type\":\"number\"}\n",
    "                                    },\n",
    "                                    \"required\":[\"price\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "    )\n",
    "        output = json.loads(agent_response.output_text)\n",
    "        return output\n",
    "    \n",
    "    def batch_predict(self, file_name, output_file='preds.jsonl'):\n",
    "        data = self.JSON_read(file_name)\n",
    "        if not data:\n",
    "            return\n",
    "        results = []\n",
    "        \n",
    "        for i, record in enumerate(tqdm(data, desc=\"Processing Test Data Predictions\")):\n",
    "            self.user_prompt = f'Predict the price for this item:\\n{json.dumps(record,indent=2)}'\n",
    "            prediction = self.call_agent()\n",
    "        \n",
    "            if prediction:\n",
    "                result = {\n",
    "                    'predicted_price': prediction['price'],\n",
    "                    'pred_id':i\n",
    "                }\n",
    "                results.append(result)\n",
    "        \n",
    "        # Saving results as JSONL\n",
    "        \n",
    "        output_dir = Path('data_output/agentic_preds/') \n",
    "        start = Path(file_name).stem #before the .jsonl\n",
    "        end = Path(file_name).suffix\n",
    "        output_file_name = f'{start}_preds{end}'\n",
    "        output_path = output_dir / output_file_name\n",
    "        \n",
    "        with output_path.open('w', encoding='utf-8') as f:\n",
    "            for result in results:\n",
    "                f.write(json.dumps(result) + '\\n')\n",
    "        \n",
    "        print(f'Saved {len(results)} predictions at {str(output_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "77cc9659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Data Predictions: 100%|██████████| 100/100 [17:38<00:00, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 predictions at data_output/agentic_preds/X_test_part_0_preds.jsonl\n",
      "Predictions were completed in 1058.4592680931091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "agent_naive = NaiveAgent(\n",
    "    system_prompt=(\n",
    "    'Predict the house price in GBP based on what you know and the information provided.'\n",
    "    )\n",
    "    )\n",
    "chunk1_response = agent_naive.batch_predict(file_name='X_test_part_0.jsonl')\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f'Predictions were completed in {duration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3f950",
   "metadata": {},
   "source": [
    "To Finish: Make OpenAI make predictions for each of the test datapoints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf8c4b",
   "metadata": {},
   "source": [
    "Try Batching API:\n",
    "Send the test set tomorrow!\n",
    "\n",
    "Try Caching your prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe421b86",
   "metadata": {},
   "source": [
    "## 2. Multi-Agent Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_list = {\n",
    "    \"1.AnalystAgent\":\n",
    "        \"\"\"\n",
    "        You're a critically thinking Data Analyst that provides helpful supporting information by creating SQL scripts focusing on:\n",
    "        1HE_district\n",
    "        1HE_PROPERTY TYPE \n",
    "        1HE_BUILT_FORM \n",
    "        CORE_TOTAL_FLOOR_AREA \n",
    "        CORE_EXTENSION_COUNT \n",
    "        CORE_NUMBER_OF_HABITABLE_ROOMS\n",
    "        \n",
    "        Generate a SQL Script to query house prices dataset and generate an aggregated supporting data relating to the input JSON and the fields above. \n",
    "        \n",
    "        Output Format:\n",
    "        SELECT <Criteria>\n",
    "        FROM <Table Names> \n",
    "        \"\"\",\n",
    "    \"2.PredictionAgent\":\n",
    "        \"\"\"\n",
    "        Using data obtained from the Analyst Agent, make a prediction for the house price in GBP for the JSON input. \n",
    "        Focus on and consider the following core features from the JSON input to make your prediction:\n",
    "        1HE_district\n",
    "        1HE_PROPERTY TYPE \n",
    "        1HE_BUILT_FORM \n",
    "        CORE_TOTAL_FLOOR_AREA \n",
    "        CORE_EXTENSION_COUNT \n",
    "        CORE_NUMBER_OF_HABITABLE_ROOMS\n",
    "        \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgent(NaiveAgent):\n",
    "    \n",
    "    def __init__(self, system_prompt, user_prompt, model='gpt-5-nano'):\n",
    "        super().__init__(system_prompt, user_prompt, model) # Initialising the parent class. \n",
    "        self.memory = []\n",
    "        \n",
    "    def initialise_agents(self, agent_list, max_agents = 5):\n",
    "        self.max_agents = max_agents\n",
    "        self.agent_list = agent_list\n",
    "        \n",
    "        if len(agent_list) > self.max_agents: # Validation to prevent high costs\n",
    "            raise ValueError(f\"You have more than {self.max_agents} agents, please reduce n_agents or increase max_agents.\")\n",
    "        \n",
    "        for agent_name, system_prompt in agent_list.items():\n",
    "            self.agent_name = agent_name\n",
    "            self.system_prompt = system_prompt\n",
    "            self.startThinking() # Should be replaced with createSingleAgent()\n",
    "                \n",
    "    def createSingleAgent(self):\n",
    "        pass \n",
    "    \n",
    "    def startThinking(self,agent):\n",
    "        # Use self.memory to input into the agent!\n",
    "        print(f\"Agent:{self.agent_name} \\nSys_Prompt:\\n{self.system_prompt}!\")\n",
    "        \n",
    "        output = None\n",
    "        self.memory.append(output)\n",
    "    \n",
    "    def main(self):\n",
    "        startThinking(agent=\"1.AnalystAgent\")\n",
    "        startThinking(agent=\"2.PredictionAgent\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4d17a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_agent = MultiAgent(system_prompt='Say Hello', user_prompt='Say Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "58ec6763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent:Analyst \n",
      "Sys_Prompt:\n",
      "\n",
      "        You're a critically thinking Data Analyst that provides helpful supporting information by creating SQL scripts focusing on:\n",
      "        1HE_district\n",
      "        1HE_PROPERTY TYPE \n",
      "        1HE_BUILT_FORM \n",
      "        CORE_TOTAL_FLOOR_AREA \n",
      "        CORE_EXTENSION_COUNT \n",
      "        CORE_NUMBER_OF_HABITABLE_ROOMS\n",
      "        \n",
      "        Generate a SQL Script to query house prices dataset and generate an aggregated supporting data relating to the input JSON and the fields above. \n",
      "        \n",
      "        Output Format:\n",
      "        SELECT <Criteria>\n",
      "        FROM <Table Names> \n",
      "        !\n",
      "Agent:Agent B \n",
      "Sys_Prompt:\n",
      "\n",
      "        Using data obtained from the Analyst Agent, make a prediction for the house price in GBP for the JSON input. \n",
      "        Focus on and consider the following core features from the JSON input to make your prediction:\n",
      "        1HE_district\n",
      "        1HE_PROPERTY TYPE \n",
      "        1HE_BUILT_FORM \n",
      "        CORE_TOTAL_FLOOR_AREA \n",
      "        CORE_EXTENSION_COUNT \n",
      "        CORE_NUMBER_OF_HABITABLE_ROOMS\n",
      "        !\n",
      "Agent:Agent C \n",
      "Sys_Prompt:\n",
      "\n",
      "        Critique the work so far and decide carefully whether to output the prediction. If the prediction does not look realistic, start the process again.\n",
      "        !\n"
     ]
    }
   ],
   "source": [
    "complex_agent.create_agents(agent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9591d35",
   "metadata": {},
   "source": [
    "Version 1:\n",
    "- 2-agent mode with a critique given average/summary stats. \n",
    "    - Tool calling perhaps?\n",
    "- n-agent with querying the dataset using SQL? \n",
    "    - Must either use pandassql or set up a SQL server. The former might be a quick win. \n",
    "    - Create an MasterAgent() inheriting from NaiveAgent(). When initialised, this will create n-naive_agents but the prompt will be the key different. \n",
    "    - NaiveAgent class may need to be refactored to be generalisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420c634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9157f10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
