{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db49ed31",
   "metadata": {},
   "source": [
    "# Baseline Naive Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9151ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb3c2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 2.14.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa23d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (2.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55935c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stratified features \n",
    "X_train = pd.read_parquet('data_output/prod_features/X_train.parquet')\n",
    "y_train = pd.read_parquet('data_output/prod_features/y_train.parquet')\n",
    "X_test = pd.read_parquet('data_output/prod_features/X_test.parquet')\n",
    "y_test = pd.read_parquet('data_output/prod_features/y_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0cbee1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partioning Complete: 87 Partitions Created\n",
      "Partioning Complete: 87 Partitions Created\n"
     ]
    }
   ],
   "source": [
    "# Partitioning data into chunks of 100 records (to monitor cost efficiency)\n",
    "output_dir = 'data_output/prod_features/json_test_files/'\n",
    "partition_size = 100\n",
    "\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "df_to_chunk ={'X_test':X_test, 'y_test':y_test}\n",
    "\n",
    "for name, file in df_to_chunk.items():\n",
    "\n",
    "    for chunk_id, chunk_df in iter(file.groupby(np.arange(len(file)) // partition_size)):\n",
    "        file_path = f'{output_dir}{name}_part_{chunk_id}.jsonl'\n",
    "        chunk_df.to_json(file_path,orient='records', lines=True)\n",
    "\n",
    "    print(f'Partioning Complete: {chunk_id} Partitions Created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dccbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveAgent:\n",
    "    def __init__(self, system_prompt = None, model = 'gpt-5-nano' ):\n",
    "        load_dotenv()\n",
    "        \n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError('OpenAI API Key not found in .env')\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.user_prompt = None\n",
    "        self.base_data_path = Path('data_output/prod_features/json_test_files/')\n",
    "        self.output_dir = Path('data_output/agentic_outputs')\n",
    "        self.input_data = None\n",
    "    \n",
    "    def JSON_read(self, file_name, output_dir='data_output'):\n",
    "        try:\n",
    "            data = []\n",
    "            self.file_path = self.base_data_path / file_name\n",
    "            with self.file_path.open('r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line.strip()))\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f'Error Loading JSON: \\n{e}')\n",
    "            return None\n",
    "    \n",
    "    def call_agent(self):   \n",
    "        str_user_prompt = str(self.user_prompt)\n",
    "        str_sys_prompt = str(self.system_prompt)\n",
    "        \n",
    "        agent_response = self.client.responses.create(\n",
    "            model = self.model,\n",
    "            input = [\n",
    "                {\n",
    "                    \"role\":\"system\",\n",
    "                    \"content\":str_sys_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":str_user_prompt\n",
    "                }\n",
    "            ],\n",
    "            text = {\n",
    "                \"format\":{\n",
    "                    \"type\":\"json_schema\",\n",
    "                    \"name\":\"agent_output\",\n",
    "                    \"strict\":True,\n",
    "                    \"schema\": {\n",
    "                        \"type\":\"object\",\n",
    "                        \"properties\":{\n",
    "                                        \"price\":{\"type\":\"number\"}\n",
    "                                    },\n",
    "                                    \"required\":[\"price\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "    )\n",
    "        output = json.loads(agent_response.output_text)\n",
    "        return output\n",
    "    \n",
    "    def batch_predict(self, file_name, output_file='preds.jsonl'):\n",
    "        data = self.JSON_read(file_name)\n",
    "        if not data:\n",
    "            return\n",
    "        results = []\n",
    "        \n",
    "        for i, record in enumerate(tqdm(data, desc=\"Processing Test Data Predictions\")):\n",
    "            self.user_prompt = f'Predict the price for this item:\\n{json.dumps(record,indent=2)}'\n",
    "            prediction = self.call_agent()\n",
    "        \n",
    "            if prediction:\n",
    "                result = {\n",
    "                    'predicted_price': prediction['price'],\n",
    "                    'pred_id':i\n",
    "                }\n",
    "                results.append(result)\n",
    "        \n",
    "        # Saving results as JSONL\n",
    "        \n",
    "        output_dir = Path('data_output/agentic_preds/') \n",
    "        start = Path(file_name).stem #before the .jsonl\n",
    "        end = Path(file_name).suffix\n",
    "        output_file_name = f'{start}_preds{end}'\n",
    "        output_path = output_dir / output_file_name\n",
    "        \n",
    "        with output_path.open('w', encoding='utf-8') as f:\n",
    "            for result in results:\n",
    "                f.write(json.dumps(result) + '\\n')\n",
    "        \n",
    "        print(f'Saved {len(results)} predictions at {str(output_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc9659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Data Predictions: 100%|██████████| 100/100 [17:38<00:00, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 predictions at data_output/agentic_preds/X_test_part_0_preds.jsonl\n",
      "Predictions were completed in 1058.4592680931091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "start_time = time.time()\n",
    "\n",
    "agent_naive = NaiveAgent(\n",
    "    system_prompt=(\n",
    "    'Predict the house price in GBP based on what you know and the information provided.'\n",
    "    )\n",
    "    )\n",
    "chunk1_response = agent_naive.batch_predict(file_name='X_test_part_0.jsonl')\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f'Predictions were completed in {duration}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c7b59239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 311629.8876407717 \n",
      "Test MAE: 177110.9 \n",
      "Test MAPE: 26.2%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Naive Model\n",
    "y_preds_fp = 'data_output/agentic_preds/X_test_part_0_preds.jsonl'\n",
    "y_actuals_fp = 'data_output/prod_features/json_test_files/y_test_part_0.jsonl'\n",
    "\n",
    "y_preds_AI = pd.read_json(y_preds_fp, lines=True)\n",
    "y_preds_AI = y_preds_AI['predicted_price'] # I only need the predicted price column.\n",
    "y_actuals= pd.read_json(y_actuals_fp, lines=True, chunksize=None)\n",
    "\n",
    "test_rmse_AI = np.sqrt(mean_squared_error(y_actuals, y_preds_AI))\n",
    "test_mae_AI = mean_absolute_error(y_actuals,y_preds_AI)\n",
    "test_mape_AI = round(mean_absolute_percentage_error(y_actuals,y_preds_AI)*100,2)\n",
    "\n",
    "\n",
    "print(f'Test RMSE: {test_rmse_AI} \\nTest MAE: {test_mae_AI} \\nTest MAPE: {test_mape_AI}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1e350c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_test_part_0_preds.jsonl']\n",
      "['y_test_part_0.jsonl']\n"
     ]
    }
   ],
   "source": [
    "# Iterating over all available the chunks for the predicitons\n",
    "number_of_partitions = 1 # Only 1 partition was predicted using openAI\n",
    "y_actuals_list = []\n",
    "y_preds_list = []\n",
    "\n",
    "for n in range(number_of_partitions): \n",
    "    y_actuals_file = f'y_test_part_{str(n)}.jsonl'\n",
    "    y_preds_file = f'X_test_part_{str(n)}_preds.jsonl'\n",
    "    \n",
    "    y_actuals_list.append(y_actuals_file)\n",
    "    y_preds_list.append(y_preds_file)\n",
    "\n",
    "print(y_preds_list)\n",
    "print(y_actuals_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2883593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 311629.8876407717 \n",
      "Test MAE: 177110.9 \n",
      "Test MAPE: 26.2%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating all available chunks:\n",
    "rmse_AI = []\n",
    "mae_AI = []\n",
    "mape_AI = []\n",
    "\n",
    "for actual,pred in zip(y_actuals_list, y_preds_list):\n",
    "    y_preds_fp = Path('data_output/agentic_preds/') / pred\n",
    "    y_actuals_fp = Path('data_output/prod_features/json_test_files/') / actual\n",
    "\n",
    "    y_preds_AI = pd.read_json(y_preds_fp, lines=True)\n",
    "    y_preds_AI = y_preds_AI['predicted_price'] # I only need the predicted price column.\n",
    "    y_actuals= pd.read_json(y_actuals_fp, lines=True, chunksize=None)\n",
    "\n",
    "    test_rmse_AI = np.sqrt(mean_squared_error(y_actuals, y_preds_AI))\n",
    "    rmse_AI.append(test_rmse_AI)\n",
    "    test_mae_AI = mean_absolute_error(y_actuals,y_preds_AI)\n",
    "    mae_AI.append(test_mae_AI)\n",
    "    test_mape_AI = round(mean_absolute_percentage_error(y_actuals,y_preds_AI)*100,2) \n",
    "    mape_AI.append(test_mape_AI)\n",
    "\n",
    "print(f'Test RMSE: {test_rmse_AI} \\nTest MAE: {test_mae_AI} \\nTest MAPE: {test_mape_AI}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe421b86",
   "metadata": {},
   "source": [
    "## 2. Multi-Agent Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d5e29ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1HE_district</th>\n",
       "      <th>1HE_CURRENT_ENERGY_RATING</th>\n",
       "      <th>1HE_POTENTIAL_ENERGY_RATING</th>\n",
       "      <th>1HE_PROPERTY_TYPE</th>\n",
       "      <th>1HE_BUILT_FORM</th>\n",
       "      <th>1HE_ENERGY_TARIFF</th>\n",
       "      <th>1HE_MAINS_GAS_FLAG</th>\n",
       "      <th>1HE_GLAZED_AREA</th>\n",
       "      <th>1HE_HOT_WATER_ENERGY_EFF</th>\n",
       "      <th>1HE_HOT_WATER_ENV_EFF</th>\n",
       "      <th>...</th>\n",
       "      <th>CORE_HEATING_COST_POTENTIAL</th>\n",
       "      <th>CORE_HOT_WATER_COST_CURRENT</th>\n",
       "      <th>CORE_HOT_WATER_COST_POTENTIAL</th>\n",
       "      <th>CORE_TOTAL_FLOOR_AREA</th>\n",
       "      <th>CORE_MULTI_GLAZE_PROPORTION</th>\n",
       "      <th>CORE_EXTENSION_COUNT</th>\n",
       "      <th>CORE_NUMBER_HABITABLE_ROOMS</th>\n",
       "      <th>CORE_NUMBER_HEATED_ROOMS</th>\n",
       "      <th>CORE_LOW_ENERGY_LIGHTING</th>\n",
       "      <th>CORE_NUMBER_OPEN_FIREPLACES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUCKINGHAMSHIRE</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>House</td>\n",
       "      <td>End-Terrace</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>327.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>88.240</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUCKINGHAMSHIRE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>House</td>\n",
       "      <td>Mid-Terrace</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>282.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>48.794</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLOUGH</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>House</td>\n",
       "      <td>Semi-Detached</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>511.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>73.000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUCKINGHAMSHIRE</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>House</td>\n",
       "      <td>Mid-Terrace</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>589.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>72.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WINDSOR AND MAIDENHEAD</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>House</td>\n",
       "      <td>Mid-Terrace</td>\n",
       "      <td>Single</td>\n",
       "      <td>Y</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>648.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>84.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1HE_district 1HE_CURRENT_ENERGY_RATING  \\\n",
       "0         BUCKINGHAMSHIRE                         D   \n",
       "1         BUCKINGHAMSHIRE                         C   \n",
       "2                  SLOUGH                         E   \n",
       "3         BUCKINGHAMSHIRE                         D   \n",
       "4  WINDSOR AND MAIDENHEAD                         F   \n",
       "\n",
       "  1HE_POTENTIAL_ENERGY_RATING 1HE_PROPERTY_TYPE 1HE_BUILT_FORM  \\\n",
       "0                           C             House    End-Terrace   \n",
       "1                           C             House    Mid-Terrace   \n",
       "2                           C             House  Semi-Detached   \n",
       "3                           D             House    Mid-Terrace   \n",
       "4                           C             House    Mid-Terrace   \n",
       "\n",
       "  1HE_ENERGY_TARIFF 1HE_MAINS_GAS_FLAG 1HE_GLAZED_AREA  \\\n",
       "0           Unknown      Not Available          Normal   \n",
       "1            Single                  Y          Normal   \n",
       "2            Single                  Y          Normal   \n",
       "3            Single                  Y          Normal   \n",
       "4            Single                  Y          Normal   \n",
       "\n",
       "  1HE_HOT_WATER_ENERGY_EFF 1HE_HOT_WATER_ENV_EFF  ...  \\\n",
       "0                     Good                  Good  ...   \n",
       "1                     Good                  Good  ...   \n",
       "2                     Good                  Good  ...   \n",
       "3                     Good                  Good  ...   \n",
       "4                  Average               Average  ...   \n",
       "\n",
       "  CORE_HEATING_COST_POTENTIAL CORE_HOT_WATER_COST_CURRENT  \\\n",
       "0                       327.0                       118.0   \n",
       "1                       282.0                        85.0   \n",
       "2                       511.0                        85.0   \n",
       "3                       589.0                        93.0   \n",
       "4                       648.0                       102.0   \n",
       "\n",
       "  CORE_HOT_WATER_COST_POTENTIAL CORE_TOTAL_FLOOR_AREA  \\\n",
       "0                         103.0                88.240   \n",
       "1                          74.0                48.794   \n",
       "2                          54.0                73.000   \n",
       "3                          82.0                72.700   \n",
       "4                          81.0                84.000   \n",
       "\n",
       "  CORE_MULTI_GLAZE_PROPORTION CORE_EXTENSION_COUNT  \\\n",
       "0                       100.0                  0.0   \n",
       "1                       100.0                  0.0   \n",
       "2                        13.0                  2.0   \n",
       "3                         0.0                  0.0   \n",
       "4                         5.0                  2.0   \n",
       "\n",
       "  CORE_NUMBER_HABITABLE_ROOMS CORE_NUMBER_HEATED_ROOMS  \\\n",
       "0                         5.0                      5.0   \n",
       "1                         3.0                      3.0   \n",
       "2                         5.0                      5.0   \n",
       "3                         4.0                      4.0   \n",
       "4                         4.0                      2.0   \n",
       "\n",
       "  CORE_LOW_ENERGY_LIGHTING CORE_NUMBER_OPEN_FIREPLACES  \n",
       "0                      0.0                         0.0  \n",
       "1                      0.0                         0.0  \n",
       "2                     83.0                         1.0  \n",
       "3                     78.0                         1.0  \n",
       "4                      0.0                         1.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "\n",
    "results = duckdb.sql('SELECT * FROM X_train LIMIT 10').df()\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5b07ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_list = {\n",
    "    \"AnalystAgent\":\n",
    "        \"\"\"\n",
    "        Research average prices for houses given the main features:\n",
    "        1HE_district\n",
    "        1HE_PROPERTY TYPE \n",
    "        1HE_BUILT_FORM \n",
    "        CORE_TOTAL_FLOOR_AREA \n",
    "        CORE_EXTENSION_COUNT \n",
    "        CORE_NUMBER_OF_HABITABLE_ROOMS\n",
    "        \n",
    "        Consider the other features if necessary and provide a short summary for the Prediction agent to predict the house price for this particular record. Limit your summary to 100 words! \n",
    "        \"\"\",\n",
    "    \"PredictionAgent\":\n",
    "        \"\"\"\n",
    "        Using data obtained from the Analyst Agent, make a prediction for the house price in GBP for the JSON input. \n",
    "        Focus on and consider the following core features from the JSON input to make your prediction but you can use the other columns should you deem it necessary:\n",
    "        1HE_district\n",
    "        1HE_PROPERTY TYPE \n",
    "        1HE_BUILT_FORM \n",
    "        CORE_TOTAL_FLOOR_AREA \n",
    "        CORE_EXTENSION_COUNT \n",
    "        CORE_NUMBER_OF_HABITABLE_ROOMS\n",
    "        \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "49afd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = str({\"1HE_district\":\"SLOUGH\",\"1HE_CURRENT_ENERGY_RATING\":\"D\",\"1HE_POTENTIAL_ENERGY_RATING\":\"B\",\"1HE_PROPERTY_TYPE\":\"House\",\"1HE_BUILT_FORM\":\"Semi-Detached\",\"1HE_ENERGY_TARIFF\":\"Single\",\"1HE_MAINS_GAS_FLAG\":\"Y\",\"1HE_GLAZED_AREA\":\"Normal\",\"1HE_HOT_WATER_ENERGY_EFF\":\"Good\",\"1HE_HOT_WATER_ENV_EFF\":\"Good\",\"1HE_WINDOWS_ENERGY_EFF\":\"Average\",\"1HE_WINDOWS_ENV_EFF\":\"Average\",\"1HE_WALLS_ENERGY_EFF\":\"Average\",\"1HE_WALLS_ENV_EFF\":\"Average\",\"1HE_ROOF_ENERGY_EFF\":\"Poor\",\"1HE_MAINHEAT_ENERGY_EFF\":\"Good\",\"1HE_MAINHEATC_ENERGY_EFF\":\"Good\",\"1HE_LIGHTING_ENERGY_EFF\":\"Very Good\",\"1HE_MECHANICAL_VENTILATION\":\"natural\",\"1HE_TENURE\":\"Owner Occupied\",\"CORE_CURRENT_ENERGY_EFFICIENCY\":67.0,\"CORE_POTENTIAL_ENERGY_EFFICIENCY\":83.0,\"CORE_ENVIRONMENT_IMPACT_CURRENT\":63.0,\"CORE_ENVIRONMENT_IMPACT_POTENTIAL\":80.0,\"CORE_ENERGY_CONSUMPTION_CURRENT\":219.0,\"CORE_ENERGY_CONSUMPTION_POTENTIAL\":105.0,\"CORE_CO2_EMISSIONS_CURRENT\":3.2,\"CORE_CO2_EMISS_CURR_PER_FLOOR_AREA\":39.0,\"CORE_CO2_EMISSIONS_POTENTIAL\":1.6,\"CORE_LIGHTING_COST_CURRENT\":72.0,\"CORE_LIGHTING_COST_POTENTIAL\":72.0,\"CORE_HEATING_COST_CURRENT\":540.0,\"CORE_HEATING_COST_POTENTIAL\":461.0,\"CORE_HOT_WATER_COST_CURRENT\":94.0,\"CORE_HOT_WATER_COST_POTENTIAL\":66.0,\"CORE_TOTAL_FLOOR_AREA\":82.0,\"CORE_MULTI_GLAZE_PROPORTION\":100.0,\"CORE_EXTENSION_COUNT\":0.0,\"CORE_NUMBER_HABITABLE_ROOMS\":5.0,\"CORE_NUMBER_HEATED_ROOMS\":5.0,\"CORE_LOW_ENERGY_LIGHTING\":100.0,\"CORE_NUMBER_OPEN_FIREPLACES\":0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgent(NaiveAgent):\n",
    "    \n",
    "    def __init__(self, agent_list,max_agents = 5, model='gpt-5-nano'):\n",
    "        super().__init__(model) # Initialising the parent class. \n",
    "        self.memory = []\n",
    "        self.max_agents = max_agents\n",
    "        self.agent_list = agent_list\n",
    "        self.analyst_sys_prompt = self.agent_list['AnalystAgent']\n",
    "        self.predictor_sys_prompt = self.agent_list['PredictionAgent']\n",
    "        self.rag_errors = 0\n",
    "        \n",
    "        #Initialising RAG database in-memory - descroped as SQL prompts were highly erroneous. \n",
    "        #self.conn = duckdb.connect(':memory:')\n",
    "        #self.conn.execute(f\"CREATE TABLE masterRAG AS SELECT * FROM '{'data_output/RAGdb/RAGdb.parquet'}'\")\n",
    "        #load_count = self.conn.execute(\"SELECT COUNT(*) FROM X_train\").fetchone()[0]\n",
    "        #print(f'Loaded {load_count} records into memory.')\n",
    "        \n",
    "        if len(agent_list) > self.max_agents: # Validation to prevent high costs\n",
    "            raise ValueError(f\"You have more than {self.max_agents} agents, please reduce n_agents or increase max_agents.\")\n",
    "        \n",
    "    def initialise_Analyst(self, start_prompt):\n",
    "        self.memory = []\n",
    "        self.memory.append(start_prompt)\n",
    "        \n",
    "        # Formatting the start prompt as a str (JSON file read in)\n",
    "        if isinstance(start_prompt, (dict, pd.Series)):\n",
    "            prompt_text = \"\\n\".join([f'{k}:{v}' for k, v in start_prompt.items()])\n",
    "        else: \n",
    "            prompt_text = str(start_prompt)\n",
    "            \n",
    "        self.analyst_response = self.client.responses.create(\n",
    "        model = self.model,\n",
    "        input = [\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":self.analyst_sys_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt_text\n",
    "            }\n",
    "        ]\n",
    "        )\n",
    "        #self.memory.append(self.analyst_response.output_text)\n",
    "        #augmentation = self.rag(sql= self.analyst_response.output_text)\n",
    "        \n",
    "        self.memory.append(\n",
    "                f'Data To Support Predicton:\\n{self.analyst_response.output_text}'\n",
    "            )\n",
    "        \n",
    "        \"\"\" \n",
    "        # Removed due to poor quality SQL scripts from AnalystAgent.\n",
    "        def rag(self, sql):\n",
    "        print(f'Starting RAG with the following SQL Query: \\n{self.analyst_response.output_text}')\n",
    "        try:\n",
    "            results = self.conn.execute(sql).fetch_df()\n",
    "            json_results = results.to_json(orient='records', indent=2)\n",
    "            return json_results\n",
    "            \n",
    "        except:\n",
    "            self.rag_errors += 1\n",
    "            print('Something went wrong generating the SQL RAG Output. RAG Failed for this records.')\n",
    "            return 'No augmentation data available.'\n",
    "        \"\"\"\n",
    "\n",
    "    def initialise_Predictor(self):\n",
    "        \n",
    "        context = '\\n'.join([str(item) for item in self.memory])\n",
    "        self.prediction_context = context\n",
    "        \n",
    "        predictor_prompt = f'Context From Previous Analysis:\\n{context}\\nMake your prediction based on this data.'\n",
    "        \n",
    "        predictor_response = self.client.responses.create(\n",
    "            model = self.model,\n",
    "            input = [\n",
    "                {\n",
    "                    \"role\":\"system\",\n",
    "                    \"content\":self.predictor_sys_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\": predictor_prompt\n",
    "                }\n",
    "            ],\n",
    "            text = {\n",
    "                \"format\":{\n",
    "                    \"type\":\"json_schema\",\n",
    "                    \"name\":\"agent_output\",\n",
    "                    \"strict\":True,\n",
    "                    \"schema\": {\n",
    "                        \"type\":\"object\",\n",
    "                        \"properties\":{\n",
    "                                        \"price\":{\"type\":\"number\"}\n",
    "                                    },\n",
    "                                    \"required\":[\"price\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "        )\n",
    "        self.batch_output = json.loads(predictor_response.output_text)\n",
    "        self.memory.append(self.batch_output)\n",
    "        #print(f'Prediction: {self.batch_output}') #Used for testing purpose\n",
    "        #print(f'Context used:{predictor_prompt} ') #Used for testing purpose\n",
    "        \n",
    "    def main(self,start_prompt):\n",
    "        self.initialise_Analyst(start_prompt=start_prompt)\n",
    "        self.initialise_Predictor()\n",
    "    \n",
    "    def batch_predict_advanced(self, file_name, output_file='preds.jsonl'):\n",
    "        \n",
    "        data = self.JSON_read(file_name)\n",
    "        batch_results = []\n",
    "        \n",
    "        for i, record in enumerate(tqdm(data, desc=\"Processing Test Data Predictions\")):\n",
    "            self.main(start_prompt=record)\n",
    "        \n",
    "            if self.batch_output:\n",
    "                result = {\n",
    "                    'predicted_price': self.batch_output['price'],\n",
    "                    'pred_id':i,\n",
    "                    'context':self.prediction_context\n",
    "                }\n",
    "                batch_results.append(result)\n",
    "        \n",
    "        # Saving results as JSONL\n",
    "        \n",
    "        output_dir = Path('data_output/advanced_agentic_preds/') \n",
    "        start = Path(file_name).stem #before the .jsonl\n",
    "        end = Path(file_name).suffix\n",
    "        output_file_name = f'{start}_preds{end}'\n",
    "        output_path = output_dir / output_file_name\n",
    "        \n",
    "        with output_path.open('w', encoding='utf-8') as f:\n",
    "            for result in batch_results:\n",
    "                f.write(json.dumps(result) + '\\n')\n",
    "        \n",
    "        print(f'Saved {len(batch_results)} predictions at {str(output_path)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eee2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Data Predictions: 100%|██████████| 3/3 [01:18<00:00, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3 predictions at data_output/advanced_agentic_preds/test_small_preds.jsonl\n",
      "Predictions were completed in 1.31 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "agent_advanced = MultiAgent(agent_list=agent_list)\n",
    "chunk1_response = agent_advanced.batch_predict_advanced(file_name='X_test_part_0.jsonl')\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f'Predictions were completed in {(duration/60):.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b7b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
